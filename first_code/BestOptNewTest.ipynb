{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Note: Environment variables set for this entire notebook session\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Set environment variables\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ[\"TF_DISABLE_METAL\"] = \"1\"  # Mac-specific\n",
    "\n",
    "import tensorflow as tf\n",
    "# Explicitly disable GPU devices\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# Verify\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"Note: Environment variables set for this entire notebook session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test matrix multiplication result:\n",
      "tf.Tensor(\n",
      "[[19. 22.]\n",
      " [43. 50.]], shape=(2, 2), dtype=float32)\n",
      "Device used: /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "# Quick test to confirm CPU-only execution\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    \n",
    "print(\"Test matrix multiplication result:\")\n",
    "print(c)\n",
    "print(\"Device used:\", c.device)  # Should show CPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from pkl files\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "with open('./Input/8-mers/mic_dframe.pkl', 'rb') as file:\n",
    "    mic_dframe = pickle.load(file)\n",
    "with open('./Input/8-mers/suscep_classes.pkl', 'rb') as file:\n",
    "    suscep_classes = pd.read_pickle(file)\n",
    "    \n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "antibiotics = mic_dframe.columns[-12:]\n",
    "\n",
    "def prob_to_onehot(y):\n",
    "    for i in range(0, y.shape[0]):\n",
    "        greater = 0\n",
    "        pos = 0\n",
    "        for j in range(0, y.shape[1]):\n",
    "            if y[i][j] >= greater:\n",
    "                greater = y[i][j]\n",
    "                pos = j\n",
    "            y[i][j] = 0.0\n",
    "        y[i][pos] = 1.0\n",
    "    return y\n",
    "\n",
    "def best_N_features(target_df, antibiotic, N):\n",
    "    path = './input/8-mers/counts/'\n",
    "    genome_ids = target_df['Genome ID'].loc[pd.notnull(target_df[antibiotic])].values\n",
    "    X = np.array([np.load(path + genome_id + '.npy') for genome_id in genome_ids])\n",
    "    y = target_df[antibiotic].loc[pd.notnull(target_df[antibiotic])].values\n",
    "    n_best = SelectKBest(chi2, k=N)\n",
    "    X_new = n_best.fit_transform(X, y*10**5)\n",
    "    kmers = np.load('./input/8-mers/kmers_basis.npy')\n",
    "    selected_kmers = [column[0]  for column in zip(kmers, n_best.get_support()) if column[1]]\n",
    "    #scores = k_best.fit(X,y).scores_\n",
    "    best_feature_df = pd.DataFrame(X_new, columns = selected_kmers)\n",
    "    return best_feature_df\n",
    "\n",
    "def class_weighting(df, antibiotic, cv):\n",
    "    # Unique mic values\n",
    "    mics = df[antibiotic].loc[pd.notnull(df[antibiotic])].unique()\n",
    "    # Samples per class\n",
    "    samples = {mic : len(df.loc[df[antibiotic]==mic]) for mic in mics}\n",
    "    # Sorted classes\n",
    "    mics = sorted([key for key in samples.keys()])\n",
    "    # total data\n",
    "    total = len(df.loc[pd.notnull(df[antibiotic])])\n",
    "    # class weights\n",
    "    class_weight = {i: (1 / samples[mic])*(total/len(mics))*(1/cv) for i, mic in enumerate(mics)}\n",
    "    \n",
    "    return class_weight\n",
    "\n",
    "def prepare_training(antibiotic):\n",
    "    kmer_dframe = best_N_features(target_df=mic_dframe, antibiotic=antibiotic, N=2000)\n",
    "\n",
    "    # Features\n",
    "    X = kmer_dframe.values\n",
    "\n",
    "    # Standardize the input data\n",
    "    scaler_X = StandardScaler().fit(X)\n",
    "    X_scaled = scaler_X.transform(X)\n",
    "\n",
    "    # Target\n",
    "    # list of MIC values\n",
    "    y = mic_dframe[antibiotic].loc[pd.notnull(mic_dframe[antibiotic])].values\n",
    "\n",
    "    # reshape the list of mics\n",
    "    y_reshape = np.reshape(y,(-1,1))\n",
    "\n",
    "    # define encoder function\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "    # transform the target categorical data to onehot code\n",
    "    y_onehot = encoder.fit_transform(y_reshape)\n",
    "\n",
    "    # Split into the training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_onehot, test_size=0.1, random_state=0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, y_onehot, X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ciprofloxacin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 51.18 seconds\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.6736694677871149\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "antibiotic = 'ciprofloxacin'\n",
    "\n",
    "model_dir = 'models'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "    # Model building functionu\n",
    "    def make_model_ciprofloxacin(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.7))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=150,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_ciprofloxacin()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=5000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "        \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**trimethoprim/sulfamethoxazole**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists at models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "antibiotic = 'trimethoprim/sulfamethoxazole'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "    # Model building function\n",
    "    def make_model_trimethoprim_sulfamethoxazole(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.007),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=150,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_trimethoprim_sulfamethoxazole()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=2000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ceftriaxone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 52.70 seconds\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step\n",
      "Test set accuracy: 0.888243831640058\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "antibiotic = 'ceftriaxone'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "    \n",
    "    # Model building function\n",
    "    def make_model_ceftriaxone(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=100,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_ceftriaxone()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=2000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gentamicin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 159.93 seconds\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.6232771822358346\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "antibiotic = 'gentamicin'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "    # Model building function\n",
    "    def make_model_gentamicin(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=1000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.7))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=500,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_gentamicin()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=4000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ceftiofur**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 32.65 seconds\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.7145061728395061\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "antibiotic = 'ceftiofur'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "    # Model building function\n",
    "    def make_model_ceftiofur(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=150,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_ceftiofur()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=1000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ampicillin**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 46.06 seconds\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.8205882352941176\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "antibiotic = 'ampicillin'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "    \n",
    "    # Model building function\n",
    "    def make_model_ampicillin(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=100,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_ampicillin()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=1000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**amoxicillin/clavulanic acid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 52.11 seconds\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.8695652173913043\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "antibiotic = 'amoxicillin/clavulanic acid'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "    # Model building function\n",
    "    def make_model_amoxicillin(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.7))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=600,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_amoxicillin()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=1000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cefoxitin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 89.47 seconds\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.7215384615384616\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "antibiotic = 'cefoxitin'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "    # Model building function\n",
    "    def make_model_cefoxitin(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=100000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=1000,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_cefoxitin()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=2500,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nalidixic acid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 318.49 seconds\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.6816816816816816\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "antibiotic = 'nalidixic acid'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "    # Model building function\n",
    "    def make_model_nalidixic_acid(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = 0.00001\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=500,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_nalidixic_acid()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=7000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tetracycline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 56.86 seconds\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.9373088685015291\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "antibiotic = 'tetracycline'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "    # Model building function\n",
    "    def make_model_tetracycline(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.7))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=100,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_tetracycline()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=1200,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**chloramphenicol**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 41.20 seconds\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.7631578947368421\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "antibiotic = 'chloramphenicol'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "\n",
    "    # Model building function\n",
    "    def make_model_chloramphenicol(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.7))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=100,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_chloramphenicol()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=1000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sulfisoxazole**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 27.41 seconds\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.6117455138662317\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "antibiotic = 'sulfisoxazole'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic) \n",
    "\n",
    "    # Model building function\n",
    "    def make_model_sulfisoxazole(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.7))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=200,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_sulfisoxazole()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=1000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Teste com novos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
