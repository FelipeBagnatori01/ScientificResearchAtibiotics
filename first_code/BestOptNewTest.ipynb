{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Note: Environment variables set for this entire notebook session\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Set environment variables\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ[\"TF_DISABLE_METAL\"] = \"1\"  # Mac-specific\n",
    "\n",
    "import tensorflow as tf\n",
    "# Explicitly disable GPU devices\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# Verify\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"Note: Environment variables set for this entire notebook session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test matrix multiplication result:\n",
      "tf.Tensor(\n",
      "[[19. 22.]\n",
      " [43. 50.]], shape=(2, 2), dtype=float32)\n",
      "Device used: /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "# Quick test to confirm CPU-only execution\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    \n",
    "print(\"Test matrix multiplication result:\")\n",
    "print(c)\n",
    "print(\"Device used:\", c.device)  # Should show CPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from pkl files\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "with open('./Input/8-mers/mic_dframe.pkl', 'rb') as file:\n",
    "    mic_dframe = pickle.load(file)\n",
    "with open('./Input/8-mers/suscep_classes.pkl', 'rb') as file:\n",
    "    suscep_classes = pd.read_pickle(file)\n",
    "    \n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "antibiotics = mic_dframe.columns[-12:]\n",
    "\n",
    "def prob_to_onehot(y):\n",
    "    for i in range(0, y.shape[0]):\n",
    "        greater = 0\n",
    "        pos = 0\n",
    "        for j in range(0, y.shape[1]):\n",
    "            if y[i][j] >= greater:\n",
    "                greater = y[i][j]\n",
    "                pos = j\n",
    "            y[i][j] = 0.0\n",
    "        y[i][pos] = 1.0\n",
    "    return y\n",
    "\n",
    "def best_N_features(target_df, antibiotic, N):\n",
    "    path = './input/8-mers/counts/'\n",
    "    genome_ids = target_df['Genome ID'].loc[pd.notnull(target_df[antibiotic])].values\n",
    "    X = np.array([np.load(path + genome_id + '.npy') for genome_id in genome_ids])\n",
    "    y = target_df[antibiotic].loc[pd.notnull(target_df[antibiotic])].values\n",
    "    n_best = SelectKBest(chi2, k=N)\n",
    "    X_new = n_best.fit_transform(X, y*10**5)\n",
    "    kmers = np.load('./input/8-mers/kmers_basis.npy')\n",
    "    selected_kmers = [column[0]  for column in zip(kmers, n_best.get_support()) if column[1]]\n",
    "    #scores = k_best.fit(X,y).scores_\n",
    "    best_feature_df = pd.DataFrame(X_new, columns = selected_kmers)\n",
    "    return best_feature_df\n",
    "\n",
    "def class_weighting(df, antibiotic, cv):\n",
    "    # Unique mic values\n",
    "    mics = df[antibiotic].loc[pd.notnull(df[antibiotic])].unique()\n",
    "    # Samples per class\n",
    "    samples = {mic : len(df.loc[df[antibiotic]==mic]) for mic in mics}\n",
    "    # Sorted classes\n",
    "    mics = sorted([key for key in samples.keys()])\n",
    "    # total data\n",
    "    total = len(df.loc[pd.notnull(df[antibiotic])])\n",
    "    # class weights\n",
    "    class_weight = {i: (1 / samples[mic])*(total/len(mics))*(1/cv) for i, mic in enumerate(mics)}\n",
    "    \n",
    "    return class_weight\n",
    "\n",
    "def prepare_training(antibiotic):\n",
    "    kmer_dframe = best_N_features(target_df=mic_dframe, antibiotic=antibiotic, N=2000)\n",
    "\n",
    "    # Features\n",
    "    X = kmer_dframe.values\n",
    "\n",
    "    # Standardize the input data\n",
    "    scaler_X = StandardScaler().fit(X)\n",
    "    X_scaled = scaler_X.transform(X)\n",
    "\n",
    "    # Target\n",
    "    # list of MIC values\n",
    "    y = mic_dframe[antibiotic].loc[pd.notnull(mic_dframe[antibiotic])].values\n",
    "\n",
    "    # reshape the list of mics\n",
    "    y_reshape = np.reshape(y,(-1,1))\n",
    "\n",
    "    # define encoder function\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "    # transform the target categorical data to onehot code\n",
    "    y_onehot = encoder.fit_transform(y_reshape)\n",
    "\n",
    "    # Split into the training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_onehot, test_size=0.1, random_state=0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, y_onehot, X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ciprofloxacin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 51.18 seconds\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.6736694677871149\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "antibiotic = 'ciprofloxacin'\n",
    "\n",
    "model_dir = 'models'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "    # Model building functionu\n",
    "    def make_model_ciprofloxacin(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.7))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=150,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_ciprofloxacin()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=5000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "        \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**trimethoprim/sulfamethoxazole**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists at models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "antibiotic = 'trimethoprim/sulfamethoxazole'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "    # Model building function\n",
    "    def make_model_trimethoprim_sulfamethoxazole(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.007),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=150,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_trimethoprim_sulfamethoxazole()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=2000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ceftriaxone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 52.70 seconds\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step\n",
      "Test set accuracy: 0.888243831640058\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "antibiotic = 'ceftriaxone'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "    \n",
    "    # Model building function\n",
    "    def make_model_ceftriaxone(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=100,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_ceftriaxone()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=2000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gentamicin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 159.93 seconds\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.6232771822358346\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "antibiotic = 'gentamicin'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "    # Model building function\n",
    "    def make_model_gentamicin(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=1000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.7))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=500,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_gentamicin()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=4000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ceftiofur**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 32.65 seconds\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.7145061728395061\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "antibiotic = 'ceftiofur'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "    # Model building function\n",
    "    def make_model_ceftiofur(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=150,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_ceftiofur()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=1000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ampicillin**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 46.06 seconds\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.8205882352941176\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "antibiotic = 'ampicillin'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "    \n",
    "    # Model building function\n",
    "    def make_model_ampicillin(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=100,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_ampicillin()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=1000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**amoxicillin/clavulanic acid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 52.11 seconds\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.8695652173913043\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "antibiotic = 'amoxicillin/clavulanic acid'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "    # Model building function\n",
    "    def make_model_amoxicillin(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.7))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=600,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_amoxicillin()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=1000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cefoxitin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 89.47 seconds\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.7215384615384616\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "antibiotic = 'cefoxitin'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "    # Model building function\n",
    "    def make_model_cefoxitin(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=100000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=1000,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_cefoxitin()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=2500,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nalidixic acid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 318.49 seconds\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.6816816816816816\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "antibiotic = 'nalidixic acid'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "    # Model building function\n",
    "    def make_model_nalidixic_acid(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = 0.00001\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=500,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_nalidixic_acid()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=7000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tetracycline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 56.86 seconds\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.9373088685015291\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "antibiotic = 'tetracycline'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "    # Model building function\n",
    "    def make_model_tetracycline(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.7))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=100,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_tetracycline()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=1200,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**chloramphenicol**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 41.20 seconds\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.7631578947368421\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "antibiotic = 'chloramphenicol'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic)\n",
    "\n",
    "\n",
    "    # Model building function\n",
    "    def make_model_chloramphenicol(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.7))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=100,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_chloramphenicol()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=1000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sulfisoxazole**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found at models. Saving new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 27.41 seconds\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test set accuracy: 0.6117455138662317\n",
      "Model successfully saved to models\n"
     ]
    }
   ],
   "source": [
    "antibiotic = 'sulfisoxazole'\n",
    "\n",
    "model_filepath = os.path.join(model_dir, 'model_'+ antibiotic[0:5] + '.keras')\n",
    "    \n",
    "# Check if the model file exists\n",
    "model_exists = os.path.exists(model_filepath)\n",
    "\n",
    "if not model_exists:\n",
    "    print(f\"No model found at {model_dir}. Saving new model...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, y_onehot, X = prepare_training(antibiotic) \n",
    "\n",
    "    # Model building function\n",
    "    def make_model_sulfisoxazole(loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=initializer,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                        use_bias=False, input_shape=[X.shape[1]]))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001,\n",
    "                                                    center=True, scale=True, \n",
    "                                                    beta_initializer='zeros', \n",
    "                                                    gamma_initializer='ones', \n",
    "                                                    moving_mean_initializer='zeros', \n",
    "                                                    moving_variance_initializer='ones'))\n",
    "        model.add(tf.keras.layers.Dropout(0.7))\n",
    "        model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "        \n",
    "\n",
    "        # Add the cross-entropy loss and accuracy metric for threshold probability\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Include an early stopping callback for convenience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor (loss or val_loss)\n",
    "        monitor='val_loss',\n",
    "        # how many epochs to wait before stopping (minimum epochs)\n",
    "        patience=200,\n",
    "        # minimium amount of change to count as an improvement\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    starttime = time.time()\n",
    "\n",
    "    class_weight = class_weighting(mic_dframe, antibiotic, cv=1)\n",
    "    # Define the model\n",
    "    model = make_model_sulfisoxazole()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        validation_split=0.3,\n",
    "        #validation_data=(X_valid, y_valid),\n",
    "        batch_size=512,\n",
    "        epochs=1000,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight = class_weight,\n",
    "        verbose=0, # hide the output because we have so many epochs\n",
    "    )\n",
    "\n",
    "    print('Training Time: {:0.2f} seconds'.format(time.time() - starttime))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = prob_to_onehot(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test set accuracy: \" + str(accuracy))\n",
    "\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Save the model\n",
    "    model.save(model_filepath)\n",
    "    print(f\"Model successfully saved to {model_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model already exists at {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Teste com novos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ciprofloxacin', 'gentamicin', 'trimethoprim/sulfamethoxazole']\n",
      "[1, 4, 12]\n"
     ]
    }
   ],
   "source": [
    "mic_dframe = pd.read_csv('/Users/febagnatori/Documents/GitHub/ScientificResearchAtibiotics/Input/dados_teste/mic_modelo.csv')\n",
    "#mic_dframe.to_excel('./Output/mic_modelo.xlsx')\n",
    "\n",
    "suscep_classes = pd.read_excel('/Users/febagnatori/Documents/GitHub/ScientificResearchAtibiotics/Input/dados_teste/suscep_classes_new_alt.xlsx')\n",
    "\n",
    "antibiotics_new = mic_dframe.columns[-18:]\n",
    "antibiotics_new = antibiotics_new.to_list()\n",
    "antibiotics_new.pop(2)\n",
    "antibiotics_new.pop(4)\n",
    "antibiotics_new.pop(5)\n",
    "antibiotics_new.pop(9)\n",
    "antibiotics_new.pop(12)\n",
    "\n",
    "# print(antibiotics)\n",
    "# print(antibiotics_new)\n",
    "\n",
    "commom_antibiotics = []\n",
    "\n",
    "for antibiotic_aux in antibiotics_new:\n",
    "    if antibiotic_aux in antibiotics:\n",
    "        commom_antibiotics.append(antibiotic_aux)\n",
    "\n",
    "print(commom_antibiotics)\n",
    "\n",
    "commom_index = []\n",
    "for i in range(len(antibiotics_new)):\n",
    "    if antibiotics_new[i] in antibiotics:\n",
    "        commom_index.append(i)\n",
    "        \n",
    "print(commom_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def best_N_features_new(target_df, antibiotic, N):\n",
    "    path = '/Users/febagnatori/Documents/GitHub/ScientificResearchAtibiotics/Input/dados_teste/Kmers 8/counts_k8_npy/counts_k8_npy/'\n",
    "    genome_ids = target_df['Gene_ID'].loc[pd.notnull(target_df[antibiotic])].values\n",
    "    \n",
    "    # Modified approach to load text files\n",
    "    X = []\n",
    "    for genome_id in genome_ids:\n",
    "        try:\n",
    "            file_path = path + genome_id + '.npy'\n",
    "            # Load as text file instead of numpy binary\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = np.array([float(x) for x in f.read().split()])\n",
    "            X.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {genome_id}.npy: {str(e)}\")\n",
    "            \n",
    "    if not X:  # If no files loaded successfully\n",
    "        raise ValueError(\"No files could be loaded successfully\")\n",
    "        \n",
    "    X = np.array(X)\n",
    "    y = target_df[antibiotic].loc[pd.notnull(target_df[antibiotic])].values\n",
    "    \n",
    "    n_best = SelectKBest(chi2, k=min(N, X.shape[1]))  # Ensure k is not larger than features count\n",
    "    X_new = n_best.fit_transform(X, y*10**5)\n",
    "    \n",
    "    # Load kmers file - check if it's also a text file\n",
    "    try:\n",
    "        with open('/Users/febagnatori/Documents/GitHub/ScientificResearchAtibiotics/Input/dados_teste/Kmers 8/combinations_8.txt', 'r') as f:\n",
    "            kmers = np.array(f.read().split())\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading kmers file: {str(e)}\")\n",
    "        # Fallback to creating generic column names\n",
    "        kmers = np.array([f'feature_{i}' for i in range(X.shape[1])])\n",
    "        \n",
    "    # Get selected features\n",
    "    selected_kmers = [column[0] for column in zip(kmers, n_best.get_support()) if column[1]]\n",
    "    \n",
    "    # Create dataframe with selected features\n",
    "    best_feature_df = pd.DataFrame(X_new, columns=selected_kmers)\n",
    "    return best_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibiotic = antibiotics_new[1]\n",
    "\n",
    "kmer_dframe = best_N_features_new(target_df=mic_dframe, antibiotic=antibiotic, N=2000)\n",
    "\n",
    "X = kmer_dframe.values\n",
    "\n",
    "# Standardize the input data\n",
    "scaler_X = StandardScaler().fit(X)\n",
    "X_scaled = scaler_X.transform(X)\n",
    "\n",
    "# Target\n",
    "# list of MIC values\n",
    "y = mic_dframe[antibiotic].loc[pd.notnull(mic_dframe[antibiotic])].values\n",
    "\n",
    "# reshape the list of mics\n",
    "y_reshape = np.reshape(y,(-1,1))\n",
    "\n",
    "# define encoder function\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# transform the target categorical data to onehot code\n",
    "y_onehot = encoder.fit_transform(y_reshape)\n",
    "\n",
    "X_test = X_scaled\n",
    "y_test = y_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ciprofloxacin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "inconsistent shapes",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m y_pred = loaded_model.predict(X_test)\n\u001b[32m      4\u001b[39m y_pred = prob_to_onehot(y_pred)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m accuracy = \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTest set accuracy: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(accuracy))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:232\u001b[39m, in \u001b[36maccuracy_score\u001b[39m\u001b[34m(y_true, y_pred, normalize, sample_weight)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type.startswith(\u001b[33m\"\u001b[39m\u001b[33mmultilabel\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m         differing_labels = count_nonzero(\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    234\u001b[39m         differing_labels = _count_nonzero(\n\u001b[32m    235\u001b[39m             y_true - y_pred, xp=xp, device=device, axis=\u001b[32m1\u001b[39m\n\u001b[32m    236\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/scipy/sparse/_base.py:577\u001b[39m, in \u001b[36m_spbase.__sub__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m issparse(other):\n\u001b[32m    576\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m other.shape != \u001b[38;5;28mself\u001b[39m.shape:\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33minconsistent shapes\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sub_sparse(other)\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m isdense(other):\n",
      "\u001b[31mValueError\u001b[39m: inconsistent shapes"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('./models/model_cipro.keras')\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred = prob_to_onehot(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test set accuracy: \" + str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
